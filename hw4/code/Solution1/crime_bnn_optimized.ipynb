{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIOSTAT 682 HW4 - Problem 1: Bayesian Neural Networks for Crime Data\n",
    "\n",
    "In this notebook we fit Bayesian neural networks with spike-and-slab priors to the\n",
    "UScrime dataset. We perform grid search over prior types (current non-centered, current\n",
    "centered, and hw3 attempt2), draws/tune values, and hidden unit counts to find optimal\n",
    "hyperparameters. We then use the best configuration to compare models with different\n",
    "numbers of hidden units using DIC, evaluate test set performance, and compare with\n",
    "Bayesian linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and set random seed for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing\n",
    "\n",
    "Load the UScrime dataset, standardize features and target, and split into train/test sets (50/50).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 2025\n",
    "np.random.seed(SEED)\n",
    "EXEC_START = time.time()\n",
    "print(f\"Started: {datetime.datetime.now().isoformat(timespec='seconds')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Define helper functions for computing DIC, convergence diagnostics, model creation,\n",
    "and parsing grid search log files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "df = pd.read_csv('../../data/UScrime.csv')\n",
    "X = df.drop('y', axis=1).values\n",
    "y = df['y'].values\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Train/test split (roughly half)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.5, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Data: {X_scaled.shape[0]} obs, {X_scaled.shape[1]} features\")\n",
    "print(f\"Train: {len(y_train)}, Test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and prior specification\n",
    "\n",
    "We define two BNN model types with spike-and-slab priors:\n",
    "\n",
    "1. **Current priors** (`create_bnn_spike_slab`): Supports both centered and non-centered\n",
    "   parameterization with Bernoulli selection variables and spike-slab standard deviations.\n",
    "\n",
    "2. **HW3 attempt2 priors** (`create_bnn_hw3_attempt2`): Precision-based spike-and-slab\n",
    "   priors using inverse precision parameters.\n",
    "\n",
    "Both models use one hidden layer with tanh activation. Helper functions compute DIC\n",
    "and convergence diagnostics (R-hat, ESS, divergences) from inference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bnn_spike_slab(X_train, y_train, q, X_test=None, use_noncentered=True):\n",
    "    \"\"\"BNN with one hidden layer and spike-and-slab priors (hw4 current)\"\"\"\n",
    "    n, p = X_train.shape\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        if use_noncentered:\n",
    "            pi1, pi2 = 0.5, 0.5\n",
    "            spike_sd, slab_sd = 0.01, 1.0\n",
    "            \n",
    "            gamma1 = pm.Bernoulli(\"gamma1\", p=pi1, shape=(p, q))\n",
    "            W1_raw = pm.Normal(\"W1_raw\", mu=0, sigma=1, shape=(p, q))\n",
    "            sd1 = spike_sd + gamma1 * (slab_sd - spike_sd)\n",
    "            W1 = pm.Deterministic(\"W1\", W1_raw * sd1)\n",
    "            b1 = pm.Normal(\"b1\", mu=0, sigma=1, shape=q)\n",
    "            \n",
    "            hidden = pm.math.tanh(pm.math.dot(X_train, W1) + b1)\n",
    "            \n",
    "            gamma2 = pm.Bernoulli(\"gamma2\", p=pi2, shape=q)\n",
    "            W2_raw = pm.Normal(\"W2_raw\", mu=0, sigma=1, shape=q)\n",
    "            sd2 = spike_sd + gamma2 * (slab_sd - spike_sd)\n",
    "            W2 = pm.Deterministic(\"W2\", W2_raw * sd2)\n",
    "            b2 = pm.Normal(\"b2\", mu=0, sigma=1)\n",
    "        else:\n",
    "            pi1, pi2 = 0.5, 0.5\n",
    "            spike_sd, slab_sd = 0.01, 1.0\n",
    "            \n",
    "            gamma1 = pm.Bernoulli(\"gamma1\", p=pi1, shape=(p, q))\n",
    "            sd1 = spike_sd + gamma1 * (slab_sd - spike_sd)\n",
    "            W1 = pm.Normal(\"W1\", mu=0, sigma=sd1, shape=(p, q))\n",
    "            b1 = pm.Normal(\"b1\", mu=0, sigma=1, shape=q)\n",
    "            \n",
    "            hidden = pm.math.tanh(pm.math.dot(X_train, W1) + b1)\n",
    "            \n",
    "            gamma2 = pm.Bernoulli(\"gamma2\", p=pi2, shape=q)\n",
    "            sd2 = spike_sd + gamma2 * (slab_sd - spike_sd)\n",
    "            W2 = pm.Normal(\"W2\", mu=0, sigma=sd2, shape=q)\n",
    "            b2 = pm.Normal(\"b2\", mu=0, sigma=1)\n",
    "        \n",
    "        mu = pm.math.dot(hidden, W2) + b2\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "        y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y_train)\n",
    "        \n",
    "        if X_test is not None:\n",
    "            hidden_test = pm.math.tanh(pm.math.dot(X_test, W1) + b1)\n",
    "            mu_test = pm.math.dot(hidden_test, W2) + b2\n",
    "            y_pred = pm.Normal(\"y_pred\", mu=mu_test, sigma=sigma, shape=X_test.shape[0])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_bnn_hw3_attempt2(X_train, y_train, q, X_test=None):\n",
    "    \"\"\"BNN with hw3/v2 attempt2 precision-based spike-and-slab priors\"\"\"\n",
    "    n, p = X_train.shape\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        alpha = pm.Normal(\"alpha\", mu=0.0, sigma=100.0)\n",
    "        \n",
    "        # Layer 1: Input -> Hidden (precision-based spike-and-slab)\n",
    "        gamma1 = pm.Bernoulli(\"gamma1\", p=0.5, shape=(p, q))\n",
    "        inv_tau2_spike = 1000.0\n",
    "        inv_tau2_slab = 0.01\n",
    "        inv_tau2_1 = (1 - gamma1) * inv_tau2_spike + gamma1 * inv_tau2_slab\n",
    "        tau2_1 = 1.0 / inv_tau2_1\n",
    "        W1 = pm.Normal(\"W1\", mu=0.0, sigma=pm.math.sqrt(tau2_1), shape=(p, q))\n",
    "        b1 = pm.Normal(\"b1\", mu=0, sigma=1, shape=q)\n",
    "        \n",
    "        hidden = pm.math.tanh(pm.math.dot(X_train, W1) + b1)\n",
    "        \n",
    "        # Layer 2: Hidden -> Output (precision-based spike-and-slab)\n",
    "        gamma2 = pm.Bernoulli(\"gamma2\", p=0.5, shape=q)\n",
    "        inv_tau2_2 = (1 - gamma2) * inv_tau2_spike + gamma2 * inv_tau2_slab\n",
    "        tau2_2 = 1.0 / inv_tau2_2\n",
    "        W2 = pm.Normal(\"W2\", mu=0.0, sigma=pm.math.sqrt(tau2_2), shape=q)\n",
    "        b2 = pm.Normal(\"b2\", mu=0, sigma=1)\n",
    "        \n",
    "        mu = pm.math.dot(hidden, W2) + b2\n",
    "        \n",
    "        inv_sigma2 = pm.Gamma(\"inv_sigma2\", alpha=0.0001, beta=0.0001)\n",
    "        sigma2 = 1.0 / inv_sigma2\n",
    "        sigma = pm.math.sqrt(sigma2)\n",
    "        \n",
    "        y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y_train)\n",
    "        \n",
    "        if X_test is not None:\n",
    "            hidden_test = pm.math.tanh(pm.math.dot(X_test, W1) + b1)\n",
    "            mu_test = pm.math.dot(hidden_test, W2) + b2\n",
    "            y_pred = pm.Normal(\"y_pred\", mu=mu_test, sigma=sigma, shape=X_test.shape[0])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_dic(idata):\n",
    "    \"\"\"Compute DIC from inference data\"\"\"\n",
    "    log_lik = idata.log_likelihood[\"y_obs\"].values\n",
    "    log_lik_flat = log_lik.reshape(-1, log_lik.shape[-1])\n",
    "    D_bar = -2 * np.mean(log_lik_flat)\n",
    "    D_theta_bar = -2 * np.sum(np.mean(log_lik_flat, axis=0))\n",
    "    p_D = D_bar - D_theta_bar\n",
    "    return D_bar + p_D\n",
    "\n",
    "\n",
    "def _compute_diagnostics(idata):\n",
    "    \"\"\"Compute R-hat, ESS, and divergence count\"\"\"\n",
    "    rhat = az.rhat(idata)\n",
    "    vars_to_check = [v for v in rhat.data_vars \n",
    "                    if v not in ['y_pred', 'gamma1', 'gamma2']]\n",
    "    \n",
    "    if len(vars_to_check) > 0:\n",
    "        max_rhat = max([float(rhat[var].max()) for var in vars_to_check])\n",
    "        ess_bulk = az.ess(idata, method=\"bulk\")\n",
    "        min_ess = min([float(ess_bulk[var].min()) for var in vars_to_check])\n",
    "    else:\n",
    "        max_rhat = np.nan\n",
    "        min_ess = np.nan\n",
    "    \n",
    "    n_divergences = int(idata.sample_stats.diverging.values.sum()) if 'diverging' in idata.sample_stats else 0\n",
    "    \n",
    "    return max_rhat, min_ess, n_divergences\n",
    "\n",
    "\n",
    "def _get_model_creator(prior_type):\n",
    "    \"\"\"Get model creation function based on prior type\"\"\"\n",
    "    if prior_type == \"current\":\n",
    "        return create_bnn_spike_slab\n",
    "    else:\n",
    "        return create_bnn_hw3_attempt2\n",
    "\n",
    "\n",
    "def _parse_gridsearch_log(log_file):\n",
    "    \"\"\"Parse grid search log file to extract results\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    if not os.path.exists(log_file):\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    with open(log_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if '[COMBO_END]' in line and 'ERROR' not in line:\n",
    "                try:\n",
    "                    match = re.search(r'prior=([^,]+), use_noncentered=([^,]+), draws=([^,]+), tune=([^,]+), q=([^,]+), DIC=([^,]+), Rhat=([^,]+), minESS=([^,]+), Divergences=([^\\s]+)', line)\n",
    "                    if match:\n",
    "                        prior_type = match.group(1)\n",
    "                        use_noncentered = match.group(2)\n",
    "                        draws = int(match.group(3))\n",
    "                        tune = int(match.group(4))\n",
    "                        q = int(match.group(5))\n",
    "                        dic = float(match.group(6))\n",
    "                        rhat = float(match.group(7))\n",
    "                        miness = float(match.group(8))\n",
    "                        divs = int(match.group(9))\n",
    "                        \n",
    "                        use_nc = True if use_noncentered == 'True' else False if use_noncentered == 'False' else None\n",
    "                        converged = (rhat < 1.01) and (divs == 0)\n",
    "                        \n",
    "                        results.append({\n",
    "                            'prior_type': prior_type,\n",
    "                            'use_noncentered': use_nc,\n",
    "                            'draws': draws,\n",
    "                            'tune': tune,\n",
    "                            'q': q,\n",
    "                            'DIC': dic,\n",
    "                            'Rhat': rhat,\n",
    "                            'minESS': miness,\n",
    "                            'Divergences': divs,\n",
    "                            'Converged': converged\n",
    "                        })\n",
    "                except Exception:\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def grid_search_bnn(X_train, y_train, log_file=\"bnn_gridsearch.log\"):\n",
    "    \"\"\"Grid search over hyperparameters\"\"\"\n",
    "    import datetime\n",
    "    \n",
    "    draws_tune_values = [1000, 2000, 5000, 10000, 20000]\n",
    "    q_values = [2, 3, 4, 5, 6]\n",
    "    \n",
    "    prior_configs = [\n",
    "        (\"current\", True),   # current non-centered\n",
    "        (\"current\", False),  # current centered\n",
    "        (\"hw3\", None),       # hw3 attempt2\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with open(log_file, \"w\") as f:\n",
    "        start_time = datetime.datetime.now()\n",
    "        f.write(f\"[GRIDSEARCH_START] {start_time.isoformat()}\\n\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"BNN GRID SEARCH\")\n",
    "    print(\"=\"*80)\n",
    "    total_combos = len(prior_configs) * len(draws_tune_values) * len(q_values)\n",
    "    print(f\"Testing {len(draws_tune_values)} x {len(q_values)} x {len(prior_configs)} = \"\n",
    "          f\"{total_combos} combinations\")\n",
    "    print(f\"  Prior configs: current (non-centered), current (centered), hw3 (attempt2)\")\n",
    "    print(f\"Logging to: {log_file}\\n\")\n",
    "    \n",
    "    combo_num = 0\n",
    "    \n",
    "    for prior_type, use_noncentered in prior_configs:\n",
    "        model_creator = _get_model_creator(prior_type)\n",
    "        \n",
    "        for draws_tune in draws_tune_values:\n",
    "            for q in q_values:\n",
    "                combo_num += 1\n",
    "                \n",
    "                if prior_type == \"current\":\n",
    "                    param_name = \"noncentered\" if use_noncentered else \"centered\"\n",
    "                    prior_label = f\"current-{param_name}\"\n",
    "                else:\n",
    "                    prior_label = \"hw3-attempt2\"\n",
    "                \n",
    "                print(f\"[{combo_num}/{total_combos}] Testing: prior={prior_label}, \"\n",
    "                      f\"draws={draws_tune}, tune={draws_tune}, q={q}\")\n",
    "                \n",
    "                combo_start = datetime.datetime.now()\n",
    "                with open(log_file, \"a\") as f:\n",
    "                    f.write(f\"[COMBO_START] {combo_start.isoformat()} - \"\n",
    "                           f\"prior={prior_type}, use_noncentered={use_noncentered}, \"\n",
    "                           f\"draws={draws_tune}, tune={draws_tune}, q={q}\\n\")\n",
    "            \n",
    "                try:\n",
    "                    # Create model once\n",
    "                    if prior_type == \"current\":\n",
    "                        model = model_creator(X_train, y_train, q, use_noncentered=use_noncentered)\n",
    "                    else:\n",
    "                        model = model_creator(X_train, y_train, q)\n",
    "                    \n",
    "                    with model:\n",
    "                        idata = pm.sample(\n",
    "                            draws=draws_tune,\n",
    "                            tune=draws_tune,\n",
    "                            target_accept=0.90,\n",
    "                            random_seed=SEED,\n",
    "                            return_inferencedata=True,\n",
    "                            init=\"adapt_diag\",\n",
    "                            chains=4,\n",
    "                            cores=1,\n",
    "                            progressbar=False\n",
    "                        )\n",
    "                        \n",
    "                        # Compute log likelihood using same model\n",
    "                        pm.compute_log_likelihood(idata)\n",
    "                    \n",
    "                    dic = _compute_dic(idata)\n",
    "                    max_rhat, min_ess, n_divergences = _compute_diagnostics(idata)\n",
    "                    \n",
    "                    combo_end = datetime.datetime.now()\n",
    "                    converged = (max_rhat < 1.01) and (n_divergences == 0)\n",
    "                    status = \"\" if converged else \" [DIVERGENCE]\"\n",
    "                    \n",
    "                    with open(log_file, \"a\") as f:\n",
    "                        f.write(f\"[COMBO_END]   {combo_end.isoformat()} - \"\n",
    "                               f\"prior={prior_type}, use_noncentered={use_noncentered}, \"\n",
    "                               f\"draws={draws_tune}, tune={draws_tune}, q={q}, \"\n",
    "                               f\"DIC={dic:.2f}, Rhat={max_rhat:.4f}, \"\n",
    "                               f\"minESS={min_ess:.0f}, Divergences={n_divergences}\"\n",
    "                               f\"{status}\\n\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        'prior_type': prior_type,\n",
    "                        'use_noncentered': use_noncentered,\n",
    "                        'draws': draws_tune,\n",
    "                        'tune': draws_tune,\n",
    "                        'q': q,\n",
    "                        'DIC': dic,\n",
    "                        'Rhat': max_rhat,\n",
    "                        'minESS': min_ess,\n",
    "                        'Divergences': n_divergences,\n",
    "                        'Converged': converged,\n",
    "                        'Duration': (combo_end - combo_start).total_seconds()\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"  ✓ DIC={dic:.2f}, R-hat={max_rhat:.4f}, \"\n",
    "                          f\"minESS={min_ess:.0f}, Divergences={n_divergences}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    combo_end = datetime.datetime.now()\n",
    "                    error_msg = str(e)[:100]\n",
    "                    \n",
    "                    with open(log_file, \"a\") as f:\n",
    "                        f.write(f\"[COMBO_END]   {combo_end.isoformat()} - \"\n",
    "                               f\"prior={prior_type}, use_noncentered={use_noncentered}, \"\n",
    "                               f\"draws={draws_tune}, tune={draws_tune}, q={q}, \"\n",
    "                               f\"ERROR: {error_msg}\\n\")\n",
    "                    \n",
    "                    print(f\"  ✗ ERROR: {error_msg}\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        'prior_type': prior_type,\n",
    "                        'use_noncentered': use_noncentered,\n",
    "                        'draws': draws_tune,\n",
    "                        'tune': draws_tune,\n",
    "                        'q': q,\n",
    "                        'DIC': np.nan,\n",
    "                        'Rhat': np.nan,\n",
    "                        'minESS': np.nan,\n",
    "                        'Divergences': np.nan,\n",
    "                        'Converged': False,\n",
    "                        'Duration': (combo_end - combo_start).total_seconds(),\n",
    "                        'Error': error_msg\n",
    "                    })\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GRID SEARCH COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    converged_results = results_df[results_df['Converged'] == True]\n",
    "    \n",
    "    if len(converged_results) > 0:\n",
    "        best_idx = converged_results['DIC'].idxmin()\n",
    "        best = converged_results.loc[best_idx]\n",
    "        if best['prior_type'] == \"current\":\n",
    "            param_name = \"noncentered\" if best['use_noncentered'] else \"centered\"\n",
    "            prior_label = f\"current-{param_name}\"\n",
    "        else:\n",
    "            prior_label = \"hw3-attempt2\"\n",
    "        print(f\"\\nBest converged model:\")\n",
    "        print(f\"  Prior: {prior_label}\")\n",
    "        print(f\"  q={int(best['q'])}, draws={int(best['draws'])}, \"\n",
    "              f\"tune={int(best['tune'])}\")\n",
    "        print(f\"  DIC={best['DIC']:.2f}, R-hat={best['Rhat']:.4f}, \"\n",
    "              f\"minESS={best['minESS']:.0f}\")\n",
    "    else:\n",
    "        print(\"\\n⚠ No fully converged models found\")\n",
    "        best_idx = results_df['Rhat'].idxmin()\n",
    "        best = results_df.loc[best_idx]\n",
    "        if best['prior_type'] == \"current\":\n",
    "            param_name = \"noncentered\" if best['use_noncentered'] else \"centered\"\n",
    "            prior_label = f\"current-{param_name}\"\n",
    "        else:\n",
    "            prior_label = \"hw3-attempt2\"\n",
    "        print(f\"\\nBest model (lowest R-hat):\")\n",
    "        print(f\"  Prior: {prior_label}\")\n",
    "        print(f\"  q={int(best['q'])}, draws={int(best['draws'])}, \"\n",
    "              f\"tune={int(best['tune'])}\")\n",
    "        print(f\"  DIC={best['DIC']:.2f}, R-hat={best['Rhat']:.4f}, \"\n",
    "              f\"minESS={best['minESS']:.0f}, Divergences={best['Divergences']:.0f}\")\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "We first check if existing grid search results are available in `bnn_gridsearch.log`.\n",
    "If at least 10 results are found, we use them. Otherwise, we run a comprehensive grid\n",
    "search over:\n",
    "- Prior types: current (non-centered), current (centered), hw3 (attempt2)\n",
    "- Draws/tune values: [1000, 2000, 5000, 10000, 20000]\n",
    "- Hidden units q: [2, 3, 4, 5, 6]\n",
    "\n",
    "Total: 75 combinations. Results are logged to `bnn_gridsearch.log`. The best\n",
    "configuration (lowest DIC among converged models, or lowest R-hat if none converged)\n",
    "is extracted and used for all subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"bnn_gridsearch.log\"\n",
    "parsed_results = _parse_gridsearch_log(log_file)\n",
    "\n",
    "if len(parsed_results) > 0 and len(parsed_results) >= 10:\n",
    "    print(f\"Found {len(parsed_results)} existing grid search results in {log_file}\")\n",
    "    grid_results_df = parsed_results\n",
    "else:\n",
    "    print(f\"Running grid search (results will be saved to {log_file})...\")\n",
    "    grid_results_df = grid_search_bnn(X_train, y_train, log_file=log_file)\n",
    "\n",
    "converged = grid_results_df[grid_results_df['Converged'] == True]\n",
    "if len(converged) > 0:\n",
    "    best_config = converged.loc[converged['DIC'].idxmin()]\n",
    "else:\n",
    "    best_config = grid_results_df.loc[grid_results_df['Rhat'].idxmin()]\n",
    "\n",
    "BEST_PRIOR_TYPE = best_config['prior_type']\n",
    "BEST_USE_NONCENTERED = best_config['use_noncentered'] if pd.notna(best_config['use_noncentered']) else True\n",
    "BEST_DRAWS = int(best_config['draws'])\n",
    "BEST_TUNE = int(best_config['tune'])\n",
    "\n",
    "print(f\"\\n✓ Best configuration:\")\n",
    "print(f\"  Prior: {BEST_PRIOR_TYPE}, Non-centered: {BEST_USE_NONCENTERED}\")\n",
    "print(f\"  Draws: {BEST_DRAWS}, Tune: {BEST_TUNE}\")\n",
    "print(f\"  DIC: {best_config['DIC']:.2f}, R-hat: {best_config['Rhat']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 1(a): Compare models with different q\n",
    "\n",
    "Using the best prior type and hyperparameters from grid search, we fit BNN models\n",
    "on the full dataset (X_scaled, y_scaled) for each $q \\in \\{2,3,4,5,6\\}$. We compute\n",
    "DIC, R-hat, ESS, and divergence counts for each model and identify the best model\n",
    "based on DIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAINS = 6\n",
    "TARGET_ACCEPT = 0.98\n",
    "q_values = [2, 3, 4, 5, 6]\n",
    "\n",
    "full_results = {}\n",
    "dic_scores = []\n",
    "model_creator = _get_model_creator(BEST_PRIOR_TYPE)\n",
    "\n",
    "for q in q_values:\n",
    "    print(f\"Fitting q={q}...\")\n",
    "    \n",
    "    if BEST_PRIOR_TYPE == \"current\":\n",
    "        model = model_creator(X_scaled, y_scaled, q, use_noncentered=BEST_USE_NONCENTERED)\n",
    "    else:\n",
    "        model = model_creator(X_scaled, y_scaled, q)\n",
    "    \n",
    "    with model:\n",
    "        idata = pm.sample(\n",
    "            draws=BEST_DRAWS, tune=BEST_TUNE, chains=CHAINS,\n",
    "            target_accept=TARGET_ACCEPT, random_seed=SEED,\n",
    "            init=\"adapt_diag\", return_inferencedata=True,\n",
    "            cores=1, progressbar=True\n",
    "        )\n",
    "        pm.compute_log_likelihood(idata)\n",
    "    \n",
    "    dic = _compute_dic(idata)\n",
    "    max_rhat, min_ess, n_div = _compute_diagnostics(idata)\n",
    "    \n",
    "    full_results[q] = idata\n",
    "    dic_scores.append({\n",
    "        'q': q,\n",
    "        'DIC': dic,\n",
    "        'R-hat': max_rhat,\n",
    "        'min_ESS': min_ess,\n",
    "        'Divergences': n_div\n",
    "    })\n",
    "    print(f\"  DIC={dic:.2f}, R-hat={max_rhat:.4f}, ESS={min_ess:.0f}, Div={n_div}\\n\")\n",
    "\n",
    "dic_df = pd.DataFrame(dic_scores).sort_values('DIC')\n",
    "print(dic_df.to_string(index=False))\n",
    "best_q = int(dic_df.iloc[0]['q'])\n",
    "print(f\"\\nBest model: q={best_q} (DIC={dic_df.iloc[0]['DIC']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1(b): Test set prediction\n",
    "\n",
    "Using the best prior type and hyperparameters from grid search, we fit BNN models\n",
    "on the training set for each $q \\\\in \\\\{2,3,4,5,6\\\\}$ and generate predictions on the\n",
    "test set. We compute RMSE, MAE, R², and correlation for each model and identify the\n",
    "best performing model based on test RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "model_creator = _get_model_creator(BEST_PRIOR_TYPE)\n",
    "\n",
    "for q in q_values:\n",
    "    print(f\"Evaluating q={q} on test set...\")\n",
    "    \n",
    "    if BEST_PRIOR_TYPE == \"current\":\n",
    "        model = model_creator(X_train, y_train, q, X_test, use_noncentered=BEST_USE_NONCENTERED)\n",
    "    else:\n",
    "        model = model_creator(X_train, y_train, q, X_test)\n",
    "    \n",
    "    with model:\n",
    "        idata = pm.sample(\n",
    "            draws=BEST_DRAWS, tune=BEST_TUNE, chains=CHAINS,\n",
    "            target_accept=TARGET_ACCEPT, random_seed=SEED,\n",
    "            init=\"adapt_diag\", return_inferencedata=True,\n",
    "            cores=1, progressbar=True\n",
    "        )\n",
    "    \n",
    "    y_pred_samples = idata.posterior[\"y_pred\"].values\n",
    "    y_pred_median = np.median(y_pred_samples.reshape(-1, len(y_test)), axis=0)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_median))\n",
    "    mae = mean_absolute_error(y_test, y_pred_median)\n",
    "    r2 = r2_score(y_test, y_pred_median)\n",
    "    corr = np.corrcoef(y_test, y_pred_median)[0, 1]\n",
    "    \n",
    "    max_rhat, _, _ = _compute_diagnostics(idata)\n",
    "    \n",
    "    test_results.append({\n",
    "        'q': q,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'Correlation': corr,\n",
    "        'R-hat': max_rhat,\n",
    "        'y_pred_samples': y_pred_samples,\n",
    "        'y_pred_median': y_pred_median\n",
    "    })\n",
    "    print(f\"  RMSE={rmse:.4f}, MAE={mae:.4f}, R²={r2:.4f}, Corr={corr:.4f}\\n\")\n",
    "\n",
    "test_df = pd.DataFrame(test_results)\n",
    "print(test_df.to_string(index=False))\n",
    "best_test_idx = test_df['RMSE'].idxmin()\n",
    "print(f\"\\nBest test performance: q={int(test_df.iloc[best_test_idx]['q'])} (RMSE={test_df.iloc[best_test_idx]['RMSE']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1(c): Compare with Bayesian linear regression\n",
    "\n",
    "We fit a Bayesian linear regression model with spike-and-slab priors (non-centered\n",
    "parameterization) using the same hyperparameters (draws, tune, chains, target_accept)\n",
    "as the BNN models. We compute test set predictions and compare performance metrics\n",
    "(RMSE, MAE, R², correlation) with the BNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting Bayesian linear regression with spike-and-slab priors...\")\n",
    "\n",
    "with pm.Model() as linear_model:\n",
    "    pi = 0.5\n",
    "    gamma_lin = pm.Bernoulli(\"gamma_lin\", p=pi, shape=X_train.shape[1])\n",
    "    spike_sd, slab_sd = 0.01, 1.0\n",
    "    \n",
    "    beta_raw = pm.Normal(\"beta_raw\", mu=0, sigma=1, shape=X_train.shape[1])\n",
    "    sd_beta = spike_sd + gamma_lin * (slab_sd - spike_sd)\n",
    "    beta = pm.Deterministic(\"beta\", beta_raw * sd_beta)\n",
    "    \n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=1)\n",
    "    mu = alpha + pm.math.dot(X_train, beta)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y_train)\n",
    "    \n",
    "    mu_test = alpha + pm.math.dot(X_test, beta)\n",
    "    y_pred = pm.Normal(\"y_pred\", mu=mu_test, sigma=sigma, shape=len(y_test))\n",
    "\n",
    "with linear_model:\n",
    "    trace_linear = pm.sample(\n",
    "        BEST_DRAWS, tune=BEST_TUNE, target_accept=TARGET_ACCEPT,\n",
    "        random_seed=SEED, return_inferencedata=True,\n",
    "        chains=CHAINS, cores=1, progressbar=True\n",
    "    )\n",
    "\n",
    "max_rhat_lin, min_ess_lin, n_div_lin = _compute_diagnostics(trace_linear)\n",
    "\n",
    "print(f\"R-hat: {max_rhat_lin:.4f}, ESS: {min_ess_lin:.0f}, Divergences: {n_div_lin}\")\n",
    "\n",
    "y_pred_linear = trace_linear.posterior[\"y_pred\"].values\n",
    "y_pred_linear_median = np.median(y_pred_linear.reshape(-1, len(y_test)), axis=0)\n",
    "\n",
    "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_linear_median))\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear_median)\n",
    "r2_linear = r2_score(y_test, y_pred_linear_median)\n",
    "corr_linear = np.corrcoef(y_test, y_pred_linear_median)[0, 1]\n",
    "\n",
    "print(f\"\\nLinear regression: RMSE={rmse_linear:.4f}, MAE={mae_linear:.4f}, R²={r2_linear:.4f}, Corr={corr_linear:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final comparison\n",
    "\n",
    "We compare the test set performance of Bayesian linear regression with all BNN models\n",
    "and identify which model performs best based on RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.bar(dic_df['q'], dic_df['DIC'], alpha=0.7, edgecolor='black', color='steelblue')\n",
    "ax.set_xlabel('Number of hidden units (q)', fontsize=11)\n",
    "ax.set_ylabel('DIC', fontsize=11)\n",
    "ax.set_title('DIC by Model Size', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(q_values)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.plot(test_df['q'], test_df['RMSE'], 'o-', linewidth=2, markersize=8, label='BNN')\n",
    "ax.axhline(rmse_linear, color='red', linestyle='--', linewidth=2, label='Linear')\n",
    "ax.set_xlabel('Number of hidden units (q)', fontsize=11)\n",
    "ax.set_ylabel('RMSE', fontsize=11)\n",
    "ax.set_title('Test RMSE Comparison', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(q_values)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[0, 2]\n",
    "ax.plot(test_df['q'], test_df['R2'], 'o-', linewidth=2, markersize=8, label='BNN', color='green')\n",
    "ax.axhline(r2_linear, color='red', linestyle='--', linewidth=2, label='Linear')\n",
    "ax.set_xlabel('Number of hidden units (q)', fontsize=11)\n",
    "ax.set_ylabel('R²', fontsize=11)\n",
    "ax.set_title('Test R² Comparison', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(q_values)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.plot(dic_df['q'], dic_df['R-hat'], 'o-', linewidth=2, markersize=8, color='purple')\n",
    "ax.axhline(1.01, color='red', linestyle='--', linewidth=1, label='Target (1.01)')\n",
    "ax.set_xlabel('Number of hidden units (q)', fontsize=11)\n",
    "ax.set_ylabel('Max R-hat', fontsize=11)\n",
    "ax.set_title('Convergence: R-hat', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(q_values)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "ax.plot(dic_df['q'], dic_df['min_ESS'], 'o-', linewidth=2, markersize=8, color='orange')\n",
    "ax.axhline(400, color='red', linestyle='--', linewidth=1, label='Target (400)')\n",
    "ax.set_xlabel('Number of hidden units (q)', fontsize=11)\n",
    "ax.set_ylabel('Min ESS', fontsize=11)\n",
    "ax.set_title('Convergence: ESS', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(q_values)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1, 2]\n",
    "best_q_plot = int(test_df.iloc[test_df['RMSE'].idxmin()]['q'])\n",
    "\n",
    "# Get predictions from test_results (already computed in Problem 1(b))\n",
    "best_result = next(r for r in test_results if r['q'] == best_q_plot)\n",
    "y_pred_best = best_result['y_pred_median']\n",
    "\n",
    "ax.scatter(y_test, y_pred_best, alpha=0.6, edgecolors='black')\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "ax.set_xlabel('Actual Crime Rate', fontsize=11)\n",
    "ax.set_ylabel('Predicted Crime Rate', fontsize=11)\n",
    "ax.set_title(f'Best BNN (q={best_q_plot}): Predicted vs Actual', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('crime_bnn_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execution summary\n",
    "\n",
    "Display total runtime for the entire notebook execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLinear regression: RMSE={rmse_linear:.4f}, R²={r2_linear:.4f}\")\n",
    "print(\"\\nBayesian neural networks:\")\n",
    "for _, row in test_df.iterrows():\n",
    "    print(f\"  q={int(row['q'])}: RMSE={row['RMSE']:.4f}, R²={row['R2']:.4f}\")\n",
    "\n",
    "best_bnn_rmse = test_df['RMSE'].min()\n",
    "best_bnn_q = int(test_df.iloc[test_df['RMSE'].idxmin()]['q'])\n",
    "\n",
    "if rmse_linear < best_bnn_rmse:\n",
    "    print(f\"\\nLinear regression performs best!\")\n",
    "else:\n",
    "    print(f\"\\nBNN (q={best_bnn_q}) performs best!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We create six plots: (1) DIC by model size, (2) Test RMSE comparison (BNN vs Linear),\n",
    "(3) Test R² comparison, (4) Convergence diagnostics (R-hat), (5) Convergence diagnostics\n",
    "(ESS), and (6) Predicted vs Actual scatter plot for the best BNN model. The figure is\n",
    "saved as `crime_bnn_results.png`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEC_END = time.time()\n",
    "elapsed = (EXEC_END - EXEC_START) / 60.0\n",
    "print(f\"\\nTotal runtime: {elapsed:.1f} minutes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
