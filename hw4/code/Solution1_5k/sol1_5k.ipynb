{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIOSTAT 682 HW4 - Bayesian Neural Networks for Crime Data (5k draws/tune)\n",
    "\n",
    "This notebook fits Bayesian neural networks with spike-and-slab priors to the UScrime dataset.\n",
    "\n",
    "**Workflow:**\n",
    "**Note:** This version uses fixed 5k draws/tune for all grid search combinations.\n",
    "1. Load and preprocess data (standardize, train/test split)\n",
    "2. **Parallelized** grid search over prior types, draws/tune, and hidden units\n",
    "3. Compare BNN models with different hidden units using DIC\n",
    "4. Evaluate test set performance\n",
    "5. Compare with Bayesian linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "SEED = 2025\n",
    "np.random.seed(SEED)\n",
    "N_WORKERS = max(1, mp.cpu_count() - 1)  # Leave one core free\n",
    "\n",
    "# Directories\n",
    "MODELS_DIR = Path(\"../../data/models/Solution1_5k\")\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Log files\n",
    "GRIDSEARCH_LOG = \"bnn_gridsearch_5k.log\"\n",
    "GENERAL_LOG = \"crime_bnn_optimized_run_5k.log\"\n",
    "\n",
    "# Clear log files at start of execution (truncate, don't delete)\n",
    "for log_file in [GRIDSEARCH_LOG, GENERAL_LOG]:\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, \"w\") as f:\n",
    "            pass  # Truncate file to clear it\n",
    "        print(f\"Cleared log file: {log_file}\")\n",
    "\n",
    "EXEC_START = time.time()\n",
    "print(f\"Started: {datetime.datetime.now().isoformat(timespec='seconds')}\")\n",
    "print(f\"Available workers for parallel grid search: {N_WORKERS}\")\n",
    "print(f\"Models will be saved to: {MODELS_DIR}\")\n",
    "print(f\"Log files cleared and ready for new run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "Load the UScrime dataset, standardize features and target, and create a 50/50 train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../../data/UScrime.csv')\n",
    "X = df.drop('y', axis=1).values\n",
    "y = df['y'].values\n",
    "\n",
    "# Standardize\n",
    "scaler_X, scaler_y = StandardScaler(), StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.5, random_state=SEED\n",
    ")\n",
    "\n",
    "n_features = X_scaled.shape[1]\n",
    "print(f\"Data: {X_scaled.shape[0]} observations, {n_features} features\")\n",
    "print(f\"Train: {len(y_train)}, Test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definitions\n",
    "\n",
    "Two BNN architectures with spike-and-slab priors:\n",
    "\n",
    "1. **Current priors**: Supports centered/non-centered parameterization with Bernoulli selection\n",
    "2. **HW3 attempt2 priors**: Precision-based spike-and-slab using inverse precision\n",
    "\n",
    "Both use a single hidden layer with tanh activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bnn_spike_slab(X_train, y_train, q, X_test=None, use_noncentered=True):\n",
    "    \"\"\"\n",
    "    Create BNN with one hidden layer and spike-and-slab priors.\n",
    "    \n",
    "    Args:\n",
    "        X_train (np.ndarray): Training features of shape (n, p)\n",
    "        y_train (np.ndarray): Training targets of shape (n,)\n",
    "        q (int): Number of hidden units\n",
    "        X_test (np.ndarray, optional): Test features for prediction. Defaults to None.\n",
    "        use_noncentered (bool): If True, use non-centered parameterization. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        pm.Model: PyMC model with spike-and-slab BNN architecture\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If X_train and y_train have incompatible shapes\n",
    "    \"\"\"\n",
    "    n, p = X_train.shape\n",
    "    pi1, pi2 = 0.5, 0.5\n",
    "    spike_sd, slab_sd = 0.01, 1.0\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        # Layer 1: Input -> Hidden\n",
    "        gamma1 = pm.Bernoulli(\"gamma1\", p=pi1, shape=(p, q))\n",
    "        sd1 = spike_sd + gamma1 * (slab_sd - spike_sd)\n",
    "        \n",
    "        if use_noncentered:\n",
    "            W1_raw = pm.Normal(\"W1_raw\", mu=0, sigma=1, shape=(p, q))\n",
    "            W1 = pm.Deterministic(\"W1\", W1_raw * sd1)\n",
    "        else:\n",
    "            W1 = pm.Normal(\"W1\", mu=0, sigma=sd1, shape=(p, q))\n",
    "        \n",
    "        b1 = pm.Normal(\"b1\", mu=0, sigma=1, shape=q)\n",
    "        hidden = pm.math.tanh(pm.math.dot(X_train, W1) + b1)\n",
    "        \n",
    "        # Layer 2: Hidden -> Output\n",
    "        gamma2 = pm.Bernoulli(\"gamma2\", p=pi2, shape=q)\n",
    "        sd2 = spike_sd + gamma2 * (slab_sd - spike_sd)\n",
    "        \n",
    "        if use_noncentered:\n",
    "            W2_raw = pm.Normal(\"W2_raw\", mu=0, sigma=1, shape=q)\n",
    "            W2 = pm.Deterministic(\"W2\", W2_raw * sd2)\n",
    "        else:\n",
    "            W2 = pm.Normal(\"W2\", mu=0, sigma=sd2, shape=q)\n",
    "        \n",
    "        b2 = pm.Normal(\"b2\", mu=0, sigma=1)\n",
    "        mu = pm.math.dot(hidden, W2) + b2\n",
    "        \n",
    "        # Likelihood\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "        pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y_train)\n",
    "        \n",
    "        # Test predictions\n",
    "        if X_test is not None:\n",
    "            hidden_test = pm.math.tanh(pm.math.dot(X_test, W1) + b1)\n",
    "            mu_test = pm.math.dot(hidden_test, W2) + b2\n",
    "            pm.Normal(\"y_pred\", mu=mu_test, sigma=sigma, shape=X_test.shape[0])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_bnn_hw3_attempt2(X_train, y_train, q, X_test=None):\n",
    "    \"\"\"\n",
    "    Create BNN with precision-based spike-and-slab priors (HW3 attempt2 style).\n",
    "    \n",
    "    Uses inverse precision parameters for spike (high precision = small variance)\n",
    "    and slab (low precision = large variance) components.\n",
    "    \n",
    "    Args:\n",
    "        X_train (np.ndarray): Training features of shape (n, p)\n",
    "        y_train (np.ndarray): Training targets of shape (n,)\n",
    "        q (int): Number of hidden units\n",
    "        X_test (np.ndarray, optional): Test features for prediction. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        pm.Model: PyMC model with precision-based spike-and-slab BNN architecture\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If X_train and y_train have incompatible shapes\n",
    "    \"\"\"\n",
    "    n, p = X_train.shape\n",
    "    inv_tau2_spike, inv_tau2_slab = 1000.0, 0.01\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        alpha = pm.Normal(\"alpha\", mu=0.0, sigma=100.0)\n",
    "        \n",
    "        # Layer 1\n",
    "        gamma1 = pm.Bernoulli(\"gamma1\", p=0.5, shape=(p, q))\n",
    "        tau2_1 = 1.0 / ((1 - gamma1) * inv_tau2_spike + gamma1 * inv_tau2_slab)\n",
    "        W1 = pm.Normal(\"W1\", mu=0.0, sigma=pm.math.sqrt(tau2_1), shape=(p, q))\n",
    "        b1 = pm.Normal(\"b1\", mu=0, sigma=1, shape=q)\n",
    "        hidden = pm.math.tanh(pm.math.dot(X_train, W1) + b1)\n",
    "        \n",
    "        # Layer 2\n",
    "        gamma2 = pm.Bernoulli(\"gamma2\", p=0.5, shape=q)\n",
    "        tau2_2 = 1.0 / ((1 - gamma2) * inv_tau2_spike + gamma2 * inv_tau2_slab)\n",
    "        W2 = pm.Normal(\"W2\", mu=0.0, sigma=pm.math.sqrt(tau2_2), shape=q)\n",
    "        b2 = pm.Normal(\"b2\", mu=0, sigma=1)\n",
    "        mu = pm.math.dot(hidden, W2) + b2\n",
    "        \n",
    "        # Likelihood with inverse-gamma prior on variance\n",
    "        inv_sigma2 = pm.Gamma(\"inv_sigma2\", alpha=0.0001, beta=0.0001)\n",
    "        sigma = pm.math.sqrt(1.0 / inv_sigma2)\n",
    "        pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y_train)\n",
    "        \n",
    "        # Test predictions\n",
    "        if X_test is not None:\n",
    "            hidden_test = pm.math.tanh(pm.math.dot(X_test, W1) + b1)\n",
    "            mu_test = pm.math.dot(hidden_test, W2) + b2\n",
    "            pm.Normal(\"y_pred\", mu=mu_test, sigma=sigma, shape=X_test.shape[0])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions\n",
    "\n",
    "Utilities for computing DIC, convergence diagnostics, and parsing grid search logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dic(idata):\n",
    "    \"\"\"\n",
    "    Compute Deviance Information Criterion (DIC) from inference data.\n",
    "    \n",
    "    Args:\n",
    "        idata (arviz.InferenceData): Inference data object containing log likelihood\n",
    "    \n",
    "    Returns:\n",
    "        float: DIC value (lower is better)\n",
    "    \n",
    "    Raises:\n",
    "        KeyError: If 'y_obs' log likelihood is not found in idata\n",
    "        AttributeError: If idata does not have log_likelihood attribute\n",
    "    \"\"\"\n",
    "    log_lik = idata.log_likelihood[\"y_obs\"].values.reshape(-1, idata.log_likelihood[\"y_obs\"].shape[-1])\n",
    "    D_bar = -2 * np.mean(log_lik)\n",
    "    D_theta_bar = -2 * np.sum(np.mean(log_lik, axis=0))\n",
    "    p_D = D_bar - D_theta_bar\n",
    "    return D_bar + p_D\n",
    "\n",
    "\n",
    "def compute_diagnostics(idata, exclude_vars=('y_pred', 'gamma1', 'gamma2')):\n",
    "    \"\"\"\n",
    "    Compute convergence diagnostics: max R-hat, min ESS, divergence count.\n",
    "    \n",
    "    Args:\n",
    "        idata (arviz.InferenceData): Inference data object\n",
    "        exclude_vars (tuple): Variable names to exclude from diagnostics. \n",
    "            Defaults to ('y_pred', 'gamma1', 'gamma2').\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (max_rhat, min_ess, n_divergences)\n",
    "            - max_rhat (float): Maximum R-hat value across all variables\n",
    "            - min_ess (float): Minimum effective sample size\n",
    "            - n_divergences (int): Number of divergent transitions\n",
    "    \n",
    "    Raises:\n",
    "        AttributeError: If idata does not have required attributes\n",
    "    \"\"\"\n",
    "    rhat = az.rhat(idata)\n",
    "    vars_to_check = [v for v in rhat.data_vars if v not in exclude_vars]\n",
    "    \n",
    "    if not vars_to_check:\n",
    "        return np.nan, np.nan, 0\n",
    "    \n",
    "    max_rhat = max(float(rhat[v].max()) for v in vars_to_check)\n",
    "    ess_bulk = az.ess(idata, method=\"bulk\")\n",
    "    min_ess = min(float(ess_bulk[v].min()) for v in vars_to_check)\n",
    "    n_div = int(idata.sample_stats.diverging.values.sum()) if 'diverging' in idata.sample_stats else 0\n",
    "    \n",
    "    return max_rhat, min_ess, n_div\n",
    "\n",
    "\n",
    "def get_model_creator(prior_type):\n",
    "    \"\"\"\n",
    "    Return appropriate model creation function based on prior type.\n",
    "    \n",
    "    Args:\n",
    "        prior_type (str): Type of prior, either \"current\" or \"hw3\"\n",
    "    \n",
    "    Returns:\n",
    "        callable: Model creation function (create_bnn_spike_slab or create_bnn_hw3_attempt2)\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If prior_type is not \"current\" or \"hw3\"\n",
    "    \"\"\"\n",
    "    return create_bnn_spike_slab if prior_type == \"current\" else create_bnn_hw3_attempt2\n",
    "\n",
    "\n",
    "def log_general(message, log_file=GENERAL_LOG):\n",
    "    \"\"\"\n",
    "    Log general progress messages to file and print to console.\n",
    "    \n",
    "    Args:\n",
    "        message (str): Message to log\n",
    "        log_file (str or Path): Path to log file. Defaults to GENERAL_LOG.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    Raises:\n",
    "        IOError: If log file cannot be written\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now().isoformat()\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"[{timestamp}] {message}\\n\")\n",
    "    print(message)\n",
    "\n",
    "\n",
    "def parse_gridsearch_log(log_file):\n",
    "    \"\"\"\n",
    "    Parse grid search log file and return results DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        log_file (str or Path): Path to grid search log file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns: prior_type, use_noncentered, draws, \n",
    "            tune, q, DIC, Rhat, minESS, Divergences, Converged\n",
    "    \n",
    "    Raises:\n",
    "        IOError: If log file cannot be read\n",
    "    \"\"\"\n",
    "    if not os.path.exists(log_file):\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    pattern = re.compile(\n",
    "        r'prior=([^,]+), use_noncentered=([^,]+), draws=([^,]+), tune=([^,]+), '\n",
    "        r'q=([^,]+), DIC=([^,]+), Rhat=([^,]+), minESS=([^,]+), Divergences=([^\\s]+)'\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    with open(log_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if '[COMBO_END]' not in line or 'ERROR' in line:\n",
    "                continue\n",
    "            match = pattern.search(line)\n",
    "            if not match:\n",
    "                continue\n",
    "            \n",
    "            use_nc = {'True': True, 'False': False, 'None': None}.get(match.group(2))\n",
    "            rhat, divs = float(match.group(7)), int(match.group(9))\n",
    "            \n",
    "            results.append({\n",
    "                'prior_type': match.group(1),\n",
    "                'use_noncentered': use_nc,\n",
    "                'draws': int(match.group(3)),\n",
    "                'tune': int(match.group(4)),\n",
    "                'q': int(match.group(5)),\n",
    "                'DIC': float(match.group(6)),\n",
    "                'Rhat': rhat,\n",
    "                'minESS': float(match.group(8)),\n",
    "                'Divergences': divs,\n",
    "                'Converged': rhat < 1.01 and divs == 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def get_model_filename(prior_type, use_noncentered, draws, tune, q, models_dir=MODELS_DIR):\n",
    "    \"\"\"\n",
    "    Generate model filename following scikit-learn conventions.\n",
    "    \n",
    "    Args:\n",
    "        prior_type (str): Type of prior (\"current\" or \"hw3\")\n",
    "        use_noncentered (bool or None): Whether non-centered parameterization is used\n",
    "        draws (int): Number of draws\n",
    "        tune (int): Number of tuning steps\n",
    "        q (int): Number of hidden units\n",
    "        models_dir (Path): Directory to save models. Defaults to MODELS_DIR.\n",
    "    \n",
    "    Returns:\n",
    "        Path: Path object for the model file\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If prior_type is not recognized\n",
    "    \"\"\"\n",
    "    if prior_type == \"current\":\n",
    "        prior_str = f\"current_{'nc' if use_noncentered else 'c'}\"\n",
    "    else:\n",
    "        prior_str = \"hw3\"\n",
    "    return models_dir / f\"bnn_{prior_str}_d{draws}_t{tune}_q{q}.pkl\"\n",
    "\n",
    "\n",
    "def save_model(idata, prior_type, use_noncentered, draws, tune, q, models_dir=MODELS_DIR):\n",
    "    \"\"\"\n",
    "    Save model using joblib (scikit-learn style).\n",
    "    \n",
    "    Args:\n",
    "        idata (arviz.InferenceData): Inference data to save\n",
    "        prior_type (str): Type of prior (\"current\" or \"hw3\")\n",
    "        use_noncentered (bool or None): Whether non-centered parameterization is used\n",
    "        draws (int): Number of draws\n",
    "        tune (int): Number of tuning steps\n",
    "        q (int): Number of hidden units\n",
    "        models_dir (Path): Directory to save models. Defaults to MODELS_DIR.\n",
    "    \n",
    "    Returns:\n",
    "        Path: Path to saved model file\n",
    "    \n",
    "    Raises:\n",
    "        IOError: If model cannot be saved\n",
    "        ValueError: If prior_type is not recognized\n",
    "    \"\"\"\n",
    "    filename = get_model_filename(prior_type, use_noncentered, draws, tune, q, models_dir)\n",
    "    dump(idata, filename, compress=3)  # compress=3 for good compression\n",
    "    return filename\n",
    "\n",
    "\n",
    "def load_model(prior_type, use_noncentered, draws, tune, q, models_dir=MODELS_DIR):\n",
    "    \"\"\"\n",
    "    Load model using joblib (scikit-learn style).\n",
    "    \n",
    "    Args:\n",
    "        prior_type (str): Type of prior (\"current\" or \"hw3\")\n",
    "        use_noncentered (bool or None): Whether non-centered parameterization is used\n",
    "        draws (int): Number of draws\n",
    "        tune (int): Number of tuning steps\n",
    "        q (int): Number of hidden units\n",
    "        models_dir (Path): Directory containing models. Defaults to MODELS_DIR.\n",
    "    \n",
    "    Returns:\n",
    "        arviz.InferenceData: Loaded inference data\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If model file does not exist\n",
    "        ValueError: If prior_type is not recognized\n",
    "    \"\"\"\n",
    "    filename = get_model_filename(prior_type, use_noncentered, draws, tune, q, models_dir)\n",
    "    if filename.exists():\n",
    "        return load(filename)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model not found: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parallelized Grid Search\n",
    "\n",
    "Search over:\n",
    "- Prior types: current (non-centered), current (centered), hw3 (attempt2)\n",
    "- Draws/tune: [5000] (fixed)\n",
    "- Hidden units q: [2, 3, 4, 5, 6]\n",
    "\n",
    "- Hidden units q: [2, 3, 4, 5, 6]\n",
    "\n",
    "Total: 15 combinations (3 prior types Ã— 5 q values), run in parallel across available CPU cores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_single_config(config):\n",
    "    \"\"\"\n",
    "    Fit a single BNN configuration. Designed to run in a separate process.\n",
    "    Saves model to disk following scikit-learn conventions.\n",
    "    \n",
    "    Args:\n",
    "        config (dict): Configuration dictionary with keys:\n",
    "            - prior_type (str): Type of prior (\"current\" or \"hw3\")\n",
    "            - use_noncentered (bool or None): Whether to use non-centered parameterization\n",
    "            - draws_tune (int): Number of draws and tuning steps\n",
    "            - q (int): Number of hidden units\n",
    "            - X_train (np.ndarray): Training features\n",
    "            - y_train (np.ndarray): Training targets\n",
    "            - seed (int): Random seed\n",
    "            - models_dir (Path, optional): Directory to save models. Defaults to 'models'.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results dictionary with keys:\n",
    "            - prior_type (str): Prior type used\n",
    "            - use_noncentered (bool or None): Parameterization used\n",
    "            - draws (int): Number of draws\n",
    "            - tune (int): Number of tuning steps\n",
    "            - q (int): Number of hidden units\n",
    "            - DIC (float): Deviance Information Criterion\n",
    "            - Rhat (float): Maximum R-hat value\n",
    "            - minESS (float): Minimum effective sample size\n",
    "            - Divergences (int): Number of divergent transitions\n",
    "            - Converged (bool): Whether model converged (R-hat < 1.01 and no divergences)\n",
    "            - Duration (float): Fitting duration in seconds\n",
    "            - model_path (str or None): Path to saved model file\n",
    "            - Error (str or None): Error message if fitting failed\n",
    "    \n",
    "    Raises:\n",
    "        KeyError: If required keys are missing from config\n",
    "        ValueError: If prior_type is not recognized\n",
    "    \"\"\"\n",
    "    import warnings\n",
    "    from pathlib import Path\n",
    "    from joblib import dump\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    prior_type = config['prior_type']\n",
    "    use_nc = config['use_noncentered']\n",
    "    draws_tune = config['draws_tune']\n",
    "    q = config['q']\n",
    "    X_train = config['X_train']\n",
    "    y_train = config['y_train']\n",
    "    seed = config['seed']\n",
    "    models_dir = Path(config.get('models_dir', 'models'))\n",
    "    models_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    model_path = None\n",
    "    \n",
    "    try:\n",
    "        # Create model\n",
    "        if prior_type == \"current\":\n",
    "            model = create_bnn_spike_slab(X_train, y_train, q, use_noncentered=use_nc)\n",
    "        else:\n",
    "            model = create_bnn_hw3_attempt2(X_train, y_train, q)\n",
    "        \n",
    "        # Sample\n",
    "        with model:\n",
    "            idata = pm.sample(\n",
    "                draws=draws_tune, tune=draws_tune, chains=4, cores=1,\n",
    "                target_accept=0.90, random_seed=seed, init=\"adapt_diag\",\n",
    "                return_inferencedata=True, progressbar=False\n",
    "            )\n",
    "            pm.compute_log_likelihood(idata)\n",
    "        \n",
    "        # Save model (scikit-learn style)\n",
    "        if prior_type == \"current\":\n",
    "            prior_str = f\"current_{'nc' if use_nc else 'c'}\"\n",
    "        else:\n",
    "            prior_str = \"hw3\"\n",
    "        model_path = models_dir / f\"bnn_{prior_str}_d{draws_tune}_t{draws_tune}_q{q}.pkl\"\n",
    "        dump(idata, model_path, compress=3)\n",
    "        \n",
    "        # Compute metrics\n",
    "        dic = compute_dic(idata)\n",
    "        max_rhat, min_ess, n_div = compute_diagnostics(idata)\n",
    "        converged = max_rhat < 1.01 and n_div == 0\n",
    "        duration = (datetime.datetime.now() - start).total_seconds()\n",
    "        \n",
    "        return {\n",
    "            'prior_type': prior_type,\n",
    "            'use_noncentered': use_nc,\n",
    "            'draws': draws_tune,\n",
    "            'tune': draws_tune,\n",
    "            'q': q,\n",
    "            'DIC': dic,\n",
    "            'Rhat': max_rhat,\n",
    "            'minESS': min_ess,\n",
    "            'Divergences': n_div,\n",
    "            'Converged': converged,\n",
    "            'Duration': duration,\n",
    "            'model_path': str(model_path),\n",
    "            'Error': None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        duration = (datetime.datetime.now() - start).total_seconds()\n",
    "        return {\n",
    "            'prior_type': prior_type,\n",
    "            'use_noncentered': use_nc,\n",
    "            'draws': draws_tune,\n",
    "            'tune': draws_tune,\n",
    "            'q': q,\n",
    "            'DIC': np.nan,\n",
    "            'Rhat': np.nan,\n",
    "            'minESS': np.nan,\n",
    "            'Divergences': np.nan,\n",
    "            'Converged': False,\n",
    "            'Duration': duration,\n",
    "            'model_path': None,\n",
    "            'Error': str(e)[:100]\n",
    "        }\n",
    "\n",
    "\n",
    "def run_parallel_grid_search(X_train, y_train, n_workers=None, \n",
    "                             gridsearch_log=GRIDSEARCH_LOG, \n",
    "                             general_log=GENERAL_LOG,\n",
    "                             models_dir=MODELS_DIR):\n",
    "    \"\"\"\n",
    "    Run parallelized grid search over BNN hyperparameters using joblib.\n",
    "    Saves all models to disk and logs progress appropriately.\n",
    "    \n",
    "    Searches over:\n",
    "    - Prior types: current (non-centered), current (centered), hw3 (attempt2)\n",
    "    - Draws/tune values: [5000] (fixed)\n",
    "    - Hidden units q: [2, 3, 4, 5, 6]\n",
    "    Total: 15 combinations (3 prior types Ã— 5 q values)\n",
    "    \n",
    "    Args:\n",
    "        X_train (np.ndarray): Training features of shape (n, p)\n",
    "        y_train (np.ndarray): Training targets of shape (n,)\n",
    "        n_workers (int, optional): Number of parallel workers. \n",
    "            Defaults to cpu_count() - 1.\n",
    "        gridsearch_log (str or Path): Path to grid search log file. \n",
    "            Defaults to GRIDSEARCH_LOG.\n",
    "        general_log (str or Path): Path to general progress log file. \n",
    "            Defaults to GENERAL_LOG.\n",
    "        models_dir (Path): Directory to save models. Defaults to MODELS_DIR.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with results for all configurations, including:\n",
    "            - prior_type, use_noncentered, draws, tune, q\n",
    "            - DIC, Rhat, minESS, Divergences\n",
    "            - Converged, Duration, model_path, Error\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If X_train and y_train have incompatible shapes\n",
    "        IOError: If log files cannot be written\n",
    "        RuntimeError: If parallel execution fails\n",
    "    \"\"\"\n",
    "    if n_workers is None:\n",
    "        n_workers = max(1, mp.cpu_count() - 1)\n",
    "    \n",
    "    models_dir = Path(models_dir)\n",
    "    models_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    draws_tune_values = [5000]\n",
    "    q_values = [2, 3, 4, 5, 6]\n",
    "    prior_configs = [\n",
    "        (\"current\", True),   # non-centered\n",
    "        (\"current\", False),  # centered\n",
    "        (\"hw3\", None),       # hw3 attempt2\n",
    "    ]\n",
    "    \n",
    "    # Build all configurations\n",
    "    configs = []\n",
    "    for prior_type, use_nc in prior_configs:\n",
    "        for draws_tune in draws_tune_values:\n",
    "            for q in q_values:\n",
    "                configs.append({\n",
    "                    'prior_type': prior_type,\n",
    "                    'use_noncentered': use_nc,\n",
    "                    'draws_tune': draws_tune,\n",
    "                    'q': q,\n",
    "                    'X_train': X_train,\n",
    "                    'y_train': y_train,\n",
    "                    'seed': SEED,\n",
    "                    'models_dir': models_dir\n",
    "                })\n",
    "    \n",
    "    total = len(configs)\n",
    "    log_general(f\"Starting parallel grid search: {total} combinations using {n_workers} workers\", general_log)\n",
    "    print(f\"Parallel Grid Search: {total} combinations using {n_workers} workers\")\n",
    "    print(f\"Grid search log: {gridsearch_log}\")\n",
    "    print(f\"General log: {general_log}\")\n",
    "    print(f\"Models directory: {models_dir}\\n\")\n",
    "    \n",
    "    # Initialize grid search log file\n",
    "    search_start = datetime.datetime.now()\n",
    "    with open(gridsearch_log, \"w\") as f:\n",
    "        f.write(f\"[GRIDSEARCH_START] {search_start.isoformat()}\\n\")\n",
    "        f.write(f\"[PARALLEL] workers={n_workers}, total_configs={total}\\n\")\n",
    "        f.write(f\"[MODELS_DIR] {models_dir}\\n\")\n",
    "    \n",
    "    # Define callback function for progress updates\n",
    "    def log_result(result, completed, total):\n",
    "        \"\"\"\n",
    "        Log a single result to both grid search log and general log.\n",
    "        \n",
    "        Args:\n",
    "            result (dict): Result dictionary from fit_single_config\n",
    "            completed (int): Number of completed configurations\n",
    "            total (int): Total number of configurations\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \n",
    "        Raises:\n",
    "            IOError: If log files cannot be written\n",
    "        \"\"\"\n",
    "        # Format prior label\n",
    "        if result['prior_type'] == \"current\":\n",
    "            prior_label = f\"current-{'nc' if result['use_noncentered'] else 'c'}\"\n",
    "        else:\n",
    "            prior_label = \"hw3\"\n",
    "        \n",
    "        # Log to grid search log\n",
    "        with open(gridsearch_log, \"a\") as f:\n",
    "            if result['Error']:\n",
    "                f.write(f\"[COMBO_END] {datetime.datetime.now().isoformat()} - \"\n",
    "                        f\"prior={result['prior_type']}, use_noncentered={result['use_noncentered']}, \"\n",
    "                        f\"draws={result['draws']}, tune={result['tune']}, q={result['q']}, \"\n",
    "                        f\"ERROR: {result['Error']}\\n\")\n",
    "                status = \"ERROR\"\n",
    "            else:\n",
    "                model_info = f\", model={result.get('model_path', 'N/A')}\" if result.get('model_path') else \"\"\n",
    "                f.write(f\"[COMBO_END] {datetime.datetime.now().isoformat()} - \"\n",
    "                        f\"prior={result['prior_type']}, use_noncentered={result['use_noncentered']}, \"\n",
    "                        f\"draws={result['draws']}, tune={result['tune']}, q={result['q']}, \"\n",
    "                        f\"DIC={result['DIC']:.2f}, Rhat={result['Rhat']:.4f}, \"\n",
    "                        f\"minESS={result['minESS']:.0f}, Divergences={result['Divergences']}\"\n",
    "                        f\"{model_info}\\n\")\n",
    "                status = \"âœ“\" if result['Converged'] else \"âš \"\n",
    "        \n",
    "        # Log to general log\n",
    "        if result['Error']:\n",
    "            log_general(f\"Grid search [{completed}/{total}]: {prior_label} d={result['draws']} q={result['q']} - ERROR: {result['Error'][:40]}\", general_log)\n",
    "        else:\n",
    "            model_saved = \"âœ“\" if result.get('model_path') else \"âœ—\"\n",
    "            log_general(f\"Grid search [{completed}/{total}]: {prior_label} d={result['draws']} q={result['q']} {status} DIC={result['DIC']:.1f} RÌ‚={result['Rhat']:.3f} Model saved: {model_saved}\", general_log)\n",
    "        \n",
    "        # Progress update to console\n",
    "        if result['Error']:\n",
    "            print(f\"[{completed:2d}/{total}] {prior_label} d={result['draws']:5d} q={result['q']} âœ— {result['Error'][:40]}\")\n",
    "        else:\n",
    "            model_indicator = \"ðŸ’¾\" if result.get('model_path') else \"âš \"\n",
    "            print(f\"[{completed:2d}/{total}] {prior_label} d={result['draws']:5d} q={result['q']} \"\n",
    "                  f\"{status} DIC={result['DIC']:.1f} RÌ‚={result['Rhat']:.3f} ({result['Duration']:.0f}s) {model_indicator}\")\n",
    "    \n",
    "    # Run in parallel using joblib (handles pickling on macOS gracefully)\n",
    "    log_general(\"Starting parallel execution...\", general_log)\n",
    "    results = Parallel(n_jobs=n_workers, backend='loky', verbose=0)(\n",
    "        delayed(fit_single_config)(cfg) for cfg in configs\n",
    "    )\n",
    "    \n",
    "    # Log all results and print progress\n",
    "    for i, result in enumerate(results, 1):\n",
    "        log_result(result, i, total)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Report best result\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    converged_df = results_df[results_df['Converged']]\n",
    "    if len(converged_df) > 0:\n",
    "        best = converged_df.loc[converged_df['DIC'].idxmin()]\n",
    "        best_msg = f\"âœ“ Best converged: DIC={best['DIC']:.2f}, q={int(best['q'])}, draws={int(best['draws'])}\"\n",
    "        print(best_msg)\n",
    "        log_general(best_msg, general_log)\n",
    "    else:\n",
    "        best = results_df.loc[results_df['Rhat'].idxmin()]\n",
    "        best_msg = f\"âš  No converged models. Best R-hat: {best['Rhat']:.4f}\"\n",
    "        print(best_msg)\n",
    "        log_general(best_msg, general_log)\n",
    "    \n",
    "    total_time = results_df['Duration'].sum()\n",
    "    wall_time = (datetime.datetime.now() - search_start).total_seconds()\n",
    "    speedup_msg = f\"Total CPU time: {total_time/60:.1f} min | Wall time: {wall_time/60:.1f} min | Speedup: {total_time/wall_time:.1f}x\"\n",
    "    print(speedup_msg)\n",
    "    log_general(speedup_msg, general_log)\n",
    "    \n",
    "    # Log model count\n",
    "    saved_models = results_df['model_path'].notna().sum()\n",
    "    model_msg = f\"Saved {saved_models}/{total} models to {models_dir}\"\n",
    "    print(model_msg)\n",
    "    log_general(model_msg, general_log)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize general log (already cleared at start, now write header)\n",
    "with open(GENERAL_LOG, \"a\") as f:\n",
    "    f.write(f\"[START] {datetime.datetime.now().isoformat()}\\n\")\n",
    "    f.write(f\"Grid search log: {GRIDSEARCH_LOG}\\n\")\n",
    "    f.write(f\"Models directory: {MODELS_DIR}\\n\\n\")\n",
    "\n",
    "log_general(\"Starting notebook execution\", GENERAL_LOG)\n",
    "\n",
    "# Load existing results or run parallel grid search\n",
    "grid_results_df = parse_gridsearch_log(GRIDSEARCH_LOG)\n",
    "\n",
    "if len(grid_results_df) >= 10:\n",
    "    msg = f\"Loaded {len(grid_results_df)} existing results from {GRIDSEARCH_LOG}\"\n",
    "    print(msg)\n",
    "    log_general(msg, GENERAL_LOG)\n",
    "else:\n",
    "    print(f\"Running parallel grid search...\")\n",
    "    log_general(\"Starting parallel grid search\", GENERAL_LOG)\n",
    "    grid_results_df = run_parallel_grid_search(\n",
    "        X_train, y_train, \n",
    "        n_workers=N_WORKERS,\n",
    "        gridsearch_log=GRIDSEARCH_LOG,\n",
    "        general_log=GENERAL_LOG,\n",
    "        models_dir=MODELS_DIR\n",
    "    )\n",
    "\n",
    "# Extract best configuration\n",
    "converged = grid_results_df[grid_results_df['Converged']]\n",
    "best_config = (converged.loc[converged['DIC'].idxmin()] if len(converged) > 0 \n",
    "               else grid_results_df.loc[grid_results_df['Rhat'].idxmin()])\n",
    "\n",
    "BEST_PRIOR_TYPE = best_config['prior_type']\n",
    "BEST_USE_NONCENTERED = best_config['use_noncentered'] if pd.notna(best_config['use_noncentered']) else True\n",
    "BEST_DRAWS = int(best_config['draws'])\n",
    "BEST_TUNE = int(best_config['tune'])\n",
    "\n",
    "best_msg = f\"\\nâœ“ Best configuration:\\n  Prior: {BEST_PRIOR_TYPE}, Non-centered: {BEST_USE_NONCENTERED}\\n  Draws: {BEST_DRAWS}, Tune: {BEST_TUNE}\\n  DIC: {best_config['DIC']:.2f}, R-hat: {best_config['Rhat']:.4f}\"\n",
    "if 'model_path' in best_config and pd.notna(best_config['model_path']):\n",
    "    best_msg += f\"\\n  Model: {best_config['model_path']}\"\n",
    "print(best_msg)\n",
    "log_general(best_msg, GENERAL_LOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Problem 1(a): Model Comparison Using DIC\n",
    "\n",
    "Fit BNN models on the full dataset for q âˆˆ {2, 3, 4, 5, 6} using the best hyperparameters.\n",
    "Compare models using DIC and convergence diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling configuration\n",
    "CHAINS = 6\n",
    "TARGET_ACCEPT = 0.98\n",
    "Q_VALUES = [2, 3, 4, 5, 6]\n",
    "\n",
    "model_creator = get_model_creator(BEST_PRIOR_TYPE)\n",
    "full_results = {}\n",
    "dic_scores = []\n",
    "\n",
    "log_general(\"Starting Problem 1(a): Model comparison using DIC\", GENERAL_LOG)\n",
    "\n",
    "for q in Q_VALUES:\n",
    "    print(f\"Fitting q={q}...\", end=\" \")\n",
    "    log_general(f\"Fitting model with q={q} for DIC comparison\", GENERAL_LOG)\n",
    "    \n",
    "    if BEST_PRIOR_TYPE == \"current\":\n",
    "        model = model_creator(X_scaled, y_scaled, q, use_noncentered=BEST_USE_NONCENTERED)\n",
    "    else:\n",
    "        model = model_creator(X_scaled, y_scaled, q)\n",
    "    \n",
    "    with model:\n",
    "        idata = pm.sample(\n",
    "            draws=BEST_DRAWS, tune=BEST_TUNE, chains=CHAINS, cores=1,\n",
    "            target_accept=TARGET_ACCEPT, random_seed=SEED, init=\"adapt_diag\",\n",
    "            return_inferencedata=True, progressbar=True\n",
    "        )\n",
    "\n",
    "    # Save test fit to pkl file\n",
    "    test_filename = get_model_filename(\n",
    "        BEST_PRIOR_TYPE, BEST_USE_NONCENTERED, BEST_DRAWS, BEST_TUNE, q\n",
    "    )\n",
    "    test_filename = test_filename.parent / f\"{test_filename.stem}_test.pkl\"\n",
    "    dump(idata, test_filename, compress=3)\n",
    "    print(f\"Saved test fit to {test_filename.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Problem 1(b): Test Set Prediction\n",
    "\n",
    "Evaluate BNN models on the held-out test set using RMSE, MAE, RÂ², and correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_general(\"Starting Problem 1(b): Test set prediction\", GENERAL_LOG)\n",
    "test_results = []\n",
    "\n",
    "for q in Q_VALUES:\n",
    "    print(f\"Evaluating q={q}...\", end=\" \")\n",
    "    log_general(f\"Evaluating model with q={q} on test set\", GENERAL_LOG)\n",
    "    \n",
    "    if BEST_PRIOR_TYPE == \"current\":\n",
    "        model = model_creator(X_train, y_train, q, X_test, use_noncentered=BEST_USE_NONCENTERED)\n",
    "    else:\n",
    "        model = model_creator(X_train, y_train, q, X_test)\n",
    "    \n",
    "    with model:\n",
    "        idata = pm.sample(\n",
    "            draws=BEST_DRAWS, tune=BEST_TUNE, chains=CHAINS, cores=1,\n",
    "            target_accept=TARGET_ACCEPT, random_seed=SEED, init=\"adapt_diag\",\n",
    "            return_inferencedata=True, progressbar=True\n",
    "        )\n",
    "    \n",
    "    # Save test fit to pkl file\n",
    "    test_filename = get_model_filename(\n",
    "        BEST_PRIOR_TYPE, BEST_USE_NONCENTERED, BEST_DRAWS, BEST_TUNE, q\n",
    "    )\n",
    "    test_filename = test_filename.parent / f\"{test_filename.stem}_test.pkl\"\n",
    "    dump(idata, test_filename, compress=3)\n",
    "    print(f\"Saved test fit to {test_filename.name}\")\n",
    "    \n",
    "    # Compute predictions (median of posterior predictive)\n",
    "    y_pred_samples = idata.posterior[\"y_pred\"].values\n",
    "    y_pred_median = np.median(y_pred_samples.reshape(-1, len(y_test)), axis=0)\n",
    "    \n",
    "    # Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_median))\n",
    "    mae = mean_absolute_error(y_test, y_pred_median)\n",
    "    r2 = r2_score(y_test, y_pred_median)\n",
    "    corr = np.corrcoef(y_test, y_pred_median)[0, 1]\n",
    "    max_rhat, _, _ = compute_diagnostics(idata)\n",
    "    \n",
    "    test_results.append({\n",
    "        'q': q, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'Correlation': corr,\n",
    "        'R-hat': max_rhat, 'y_pred_median': y_pred_median\n",
    "    })\n",
    "    result_msg = f\"q={q}: RMSE={rmse:.4f}, RÂ²={r2:.4f}\"\n",
    "    print(f\"RMSE={rmse:.4f}, RÂ²={r2:.4f}\")\n",
    "    log_general(result_msg, GENERAL_LOG)\n",
    "\n",
    "test_df = pd.DataFrame(test_results)\n",
    "print(\"\\n\" + test_df[['q', 'RMSE', 'MAE', 'R2', 'Correlation']].to_string(index=False))\n",
    "\n",
    "best_test_q = int(test_df.loc[test_df['RMSE'].idxmin(), 'q'])\n",
    "best_test_msg = f\"Best test performance: q={best_test_q} (RMSE={test_df['RMSE'].min():.4f})\"\n",
    "print(f\"\\nâœ“ {best_test_msg}\")\n",
    "log_general(f\"Problem 1(b) complete: {best_test_msg}\", GENERAL_LOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Problem 1(c): Comparison with Bayesian Linear Regression\n",
    "\n",
    "Fit Bayesian linear regression with spike-and-slab priors using the same hyperparameters.\n",
    "Compare test set performance with BNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_general(\"Starting Problem 1(c): Comparison with Bayesian linear regression\", GENERAL_LOG)\n",
    "print(\"Fitting Bayesian linear regression...\")\n",
    "\n",
    "with pm.Model() as linear_model:\n",
    "    # Spike-and-slab priors (non-centered)\n",
    "    pi = 0.5\n",
    "    spike_sd, slab_sd = 0.01, 1.0\n",
    "    \n",
    "    gamma_lin = pm.Bernoulli(\"gamma_lin\", p=pi, shape=X_train.shape[1])\n",
    "    beta_raw = pm.Normal(\"beta_raw\", mu=0, sigma=1, shape=X_train.shape[1])\n",
    "    sd_beta = spike_sd + gamma_lin * (slab_sd - spike_sd)\n",
    "    beta = pm.Deterministic(\"beta\", beta_raw * sd_beta)\n",
    "    \n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=1)\n",
    "    mu = alpha + pm.math.dot(X_train, beta)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y_train)\n",
    "    \n",
    "    # Test predictions\n",
    "    mu_test = alpha + pm.math.dot(X_test, beta)\n",
    "    pm.Normal(\"y_pred\", mu=mu_test, sigma=sigma, shape=len(y_test))\n",
    "\n",
    "with linear_model:\n",
    "    trace_linear = pm.sample(\n",
    "        BEST_DRAWS, tune=BEST_TUNE, chains=CHAINS, cores=1,\n",
    "        target_accept=TARGET_ACCEPT, random_seed=SEED,\n",
    "        return_inferencedata=True, progressbar=True\n",
    "    )\n",
    "\n",
    "# Save linear regression test fit to pkl file\n",
    "linear_test_filename = MODELS_DIR / f\"linear_regression_test_d{BEST_DRAWS}_t{BEST_TUNE}.pkl\"\n",
    "dump(trace_linear, linear_test_filename, compress=3)\n",
    "print(f\"Saved linear regression test fit to {linear_test_filename.name}\")\n",
    "\n",
    "max_rhat_lin, min_ess_lin, n_div_lin = compute_diagnostics(trace_linear)\n",
    "print(f\"R-hat: {max_rhat_lin:.4f}, ESS: {min_ess_lin:.0f}, Divergences: {n_div_lin}\")\n",
    "\n",
    "# Linear model predictions\n",
    "y_pred_linear = trace_linear.posterior[\"y_pred\"].values\n",
    "y_pred_linear_median = np.median(y_pred_linear.reshape(-1, len(y_test)), axis=0)\n",
    "\n",
    "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_linear_median))\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear_median)\n",
    "r2_linear = r2_score(y_test, y_pred_linear_median)\n",
    "corr_linear = np.corrcoef(y_test, y_pred_linear_median)[0, 1]\n",
    "\n",
    "linear_msg = f\"Linear Regression: RMSE={rmse_linear:.4f}, MAE={mae_linear:.4f}, RÂ²={r2_linear:.4f}, Corr={corr_linear:.4f}\"\n",
    "print(f\"\\n{linear_msg}\")\n",
    "log_general(linear_msg, GENERAL_LOG)\n",
    "log_general(\"Problem 1(c) complete\", GENERAL_LOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Comparison and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nBayesian Linear Regression: RMSE={rmse_linear:.4f}, RÂ²={r2_linear:.4f}\")\n",
    "print(\"\\nBayesian Neural Networks:\")\n",
    "for _, row in test_df.iterrows():\n",
    "    print(f\"  q={int(row['q'])}: RMSE={row['RMSE']:.4f}, RÂ²={row['R2']:.4f}\")\n",
    "\n",
    "best_bnn_rmse = test_df['RMSE'].min()\n",
    "best_bnn_q = int(test_df.loc[test_df['RMSE'].idxmin(), 'q'])\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "if rmse_linear < best_bnn_rmse:\n",
    "    print(f\"âœ“ Winner: Linear Regression (RMSE={rmse_linear:.4f})\")\n",
    "else:\n",
    "    print(f\"âœ“ Winner: BNN with q={best_bnn_q} (RMSE={best_bnn_rmse:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualization\n",
    "\n",
    "Create a comprehensive 6-panel figure showing:\n",
    "1. DIC by model size\n",
    "2. Test RMSE comparison (BNN vs Linear)\n",
    "3. Test RÂ² comparison\n",
    "4. Convergence diagnostics (R-hat)\n",
    "5. Convergence diagnostics (ESS)\n",
    "6. Predicted vs Actual for best BNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# Panel 1: DIC by model size\n",
    "ax = axes[0, 0]\n",
    "ax.bar(dic_df['q'], dic_df['DIC'], alpha=0.7, edgecolor='black', color='steelblue')\n",
    "ax.set_xlabel('Hidden units (q)')\n",
    "ax.set_ylabel('DIC')\n",
    "ax.set_title('DIC by Model Size', fontweight='bold')\n",
    "ax.set_xticks(Q_VALUES)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel 2: Test RMSE comparison\n",
    "ax = axes[0, 1]\n",
    "ax.plot(test_df['q'], test_df['RMSE'], 'o-', lw=2, ms=8, label='BNN')\n",
    "ax.axhline(rmse_linear, color='red', ls='--', lw=2, label='Linear')\n",
    "ax.set_xlabel('Hidden units (q)')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Test RMSE Comparison', fontweight='bold')\n",
    "ax.set_xticks(Q_VALUES)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: Test RÂ² comparison\n",
    "ax = axes[0, 2]\n",
    "ax.plot(test_df['q'], test_df['R2'], 'o-', lw=2, ms=8, label='BNN', color='green')\n",
    "ax.axhline(r2_linear, color='red', ls='--', lw=2, label='Linear')\n",
    "ax.set_xlabel('Hidden units (q)')\n",
    "ax.set_ylabel('RÂ²')\n",
    "ax.set_title('Test RÂ² Comparison', fontweight='bold')\n",
    "ax.set_xticks(Q_VALUES)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 4: R-hat convergence\n",
    "ax = axes[1, 0]\n",
    "ax.plot(dic_df['q'], dic_df['R-hat'], 'o-', lw=2, ms=8, color='purple')\n",
    "ax.axhline(1.01, color='red', ls='--', lw=1, label='Target (1.01)')\n",
    "ax.set_xlabel('Hidden units (q)')\n",
    "ax.set_ylabel('Max R-hat')\n",
    "ax.set_title('Convergence: R-hat', fontweight='bold')\n",
    "ax.set_xticks(Q_VALUES)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 5: ESS convergence\n",
    "ax = axes[1, 1]\n",
    "ax.plot(dic_df['q'], dic_df['min_ESS'], 'o-', lw=2, ms=8, color='orange')\n",
    "ax.axhline(400, color='red', ls='--', lw=1, label='Target (400)')\n",
    "ax.set_xlabel('Hidden units (q)')\n",
    "ax.set_ylabel('Min ESS')\n",
    "ax.set_title('Convergence: ESS', fontweight='bold')\n",
    "ax.set_xticks(Q_VALUES)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 6: Predicted vs Actual\n",
    "ax = axes[1, 2]\n",
    "best_result = test_df.loc[test_df['RMSE'].idxmin()]\n",
    "y_pred_best = best_result['y_pred_median']\n",
    "ax.scatter(y_test, y_pred_best, alpha=0.6, edgecolors='black')\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax.set_xlabel('Actual Crime Rate')\n",
    "ax.set_ylabel('Predicted Crime Rate')\n",
    "ax.set_title(f'Best BNN (q={int(best_result[\"q\"])}): Predicted vs Actual', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('crime_bnn_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure saved: crime_bnn_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Execution Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = (time.time() - EXEC_START) / 60.0\n",
    "finish_msg = f\"Total runtime: {elapsed:.1f} minutes\"\n",
    "print(finish_msg)\n",
    "print(f\"Finished: {datetime.datetime.now().isoformat(timespec='seconds')}\")\n",
    "log_general(finish_msg, GENERAL_LOG)\n",
    "log_general(f\"Notebook execution completed at {datetime.datetime.now().isoformat(timespec='seconds')}\", GENERAL_LOG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
